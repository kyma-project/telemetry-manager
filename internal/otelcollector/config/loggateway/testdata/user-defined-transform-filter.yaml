extensions:
    health_check:
        endpoint: ${MY_POD_IP}:13133
    pprof:
        endpoint: 127.0.0.1:1777
service:
    pipelines:
        logs/test1:
            receivers:
                - otlp
            processors:
                - memory_limiter
                - transform/set-observed-time-if-zero
                - k8sattributes
                - istio_noise_filter
                - transform/insert-cluster-attributes
                - service_enrichment
                - transform/drop-kyma-attributes
                - istio_enrichment
                - transform/user-defined-test1
                - filter/user-defined-test1
                - batch
            exporters:
                - otlp_grpc/test1
    telemetry:
        metrics:
            readers:
                - pull:
                    exporter:
                        prometheus:
                            host: ${MY_POD_IP}
                            port: 8888
        logs:
            level: info
            encoding: json
    extensions:
        - health_check
        - pprof
receivers:
    otlp:
        protocols:
            http:
                endpoint: ${MY_POD_IP}:4318
            grpc:
                endpoint: ${MY_POD_IP}:4317
processors:
    batch:
        send_batch_size: 512
        timeout: 10s
        send_batch_max_size: 512
    filter/user-defined-test1:
        error_mode: ignore
        logs:
            log_record:
                - IsMatch(log.attributes["foo"], ".*bar.*")
    istio_enrichment:
        scope_version: 1.0.0
    istio_noise_filter: {}
    k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        extract:
            metadata:
                - k8s.pod.name
                - k8s.node.name
                - k8s.namespace.name
                - k8s.deployment.name
                - k8s.statefulset.name
                - k8s.daemonset.name
                - k8s.cronjob.name
                - k8s.job.name
            labels:
                - from: pod
                  key: app.kubernetes.io/name
                  tag_name: kyma.kubernetes_io_app_name
                - from: pod
                  key: app
                  tag_name: kyma.app_name
                - from: node
                  key: topology.kubernetes.io/region
                  tag_name: cloud.region
                - from: node
                  key: topology.kubernetes.io/zone
                  tag_name: cloud.availability_zone
                - from: node
                  key: node.kubernetes.io/instance-type
                  tag_name: host.type
                - from: node
                  key: kubernetes.io/arch
                  tag_name: host.arch
        pod_association:
            - sources:
                - from: resource_attribute
                  name: k8s.pod.ip
            - sources:
                - from: resource_attribute
                  name: k8s.pod.uid
            - sources:
                - from: connection
    memory_limiter:
        check_interval: 1s
        limit_percentage: 75
        spike_limit_percentage: 15
    service_enrichment:
        resource_attributes:
            - kyma.kubernetes_io_app_name
            - kyma.app_name
    transform/drop-kyma-attributes:
        error_mode: ignore
        log_statements:
            - statements:
                - delete_matching_keys(resource.attributes, "kyma.*")
    transform/insert-cluster-attributes:
        error_mode: ignore
        log_statements:
            - statements:
                - set(resource.attributes["k8s.cluster.name"], "${KUBERNETES_SERVICE_HOST}") where resource.attributes["k8s.cluster.name"] == nil or resource.attributes["k8s.cluster.name"] == ""
                - set(resource.attributes["k8s.cluster.uid"], "") where resource.attributes["k8s.cluster.uid"] == nil or resource.attributes["k8s.cluster.uid"] == ""
                - set(resource.attributes["cloud.provider"], "test-cloud-provider") where resource.attributes["cloud.provider"] == nil or resource.attributes["cloud.provider"] == ""
    transform/set-observed-time-if-zero:
        error_mode: ignore
        log_statements:
            - statements:
                - set(log.observed_time, Now())
              conditions:
                - log.observed_time_unix_nano == 0
    transform/user-defined-test1:
        error_mode: ignore
        log_statements:
            - statements:
                - set(attributes["log.level"], "error")
                - set(body, "transformed2")
              conditions:
                - IsMatch(body, ".*error.*")
exporters:
    otlp_grpc/test1:
        endpoint: ${OTLP_ENDPOINT_TEST1}
        sending_queue:
            enabled: true
            queue_size: 256
        retry_on_failure:
            enabled: true
            initial_interval: 5s
            max_interval: 30s
            max_elapsed_time: 300s
